# -*- coding: utf-8 -*-
"""WS_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16iOrKhr1cczOwWwiNSBIG54pZCZSilBb
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from scipy.stats import pearsonr
import scipy.stats as stats

def lack_of_fit_test(a, b, critical, choice):
  if choice == 1:
    # t - test
    t_statistic, p_value = stats.ttest_ind(a, b)
    print("t_statistic value : ",t_statistic)
    print("p value : ",p_value)
    if p_value < critical:
      print("Null hypothesis accepted")
    else:
      print("Null hypothesis rejected")

  else:
    # normal - test
    n_statistic, p = stats.normaltest(a, b)
    print("normal test value : ",n_statistic)
    if n_statistic < critical:
      print("Null hypothesis rejected")
    else:
      print("Null hypothesis accepted")

"""## **Question 1**"""

temp = [200, 250, 200, 250, 189.65, 260.35, 225, 225, 225, 225, 225, 225]
temp = np.array(temp)
conv = [43, 78, 69, 73, 48, 78, 65, 74, 76, 79, 83, 81]
conv = np.array(conv)

reg = LinearRegression()

reg.fit(temp.reshape(-1, 1), conv.reshape(-1, 1))

a1 = reg.coef_
b1 = reg.intercept_
a1[0][0], b1[0]

"""**Line equation** is  conv_hat = 0.40716148138368896 * temp + (-21.027999977996686)"""

conv_hat = reg.predict(temp.reshape(-1, 1))
conv_hat

r2_score(conv, conv_hat)

if len(temp) < 30:
  lack_of_fit_test(conv, conv_hat, 0.5, 1)

else:
  lack_of_fit_test(conv, conv_hat, 0.5, 2)

plt.scatter(temp, conv, color='b')
plt.plot(temp, conv_hat, color='r')

"""## **Question 2**"""

drive_in_time = [195, 255, 195, 255, 255, 255, 255, 195, 255, 255, 255, 255, 255, 340]
dose = [4, 4, 4.6, 4.6, 4.2, 4.1, 4.6, 4.3, 4.3, 4, 4.7, 4.3, 4.72, 4.3]
gain = [1004, 1636, 852, 1506, 1272, 1270, 1269, 903, 1555, 1260, 1146, 1276, 1225, 1321]

gain = np.array(gain)
drive_in_time = np.array(drive_in_time)
dose = np.array(dose)

reg1 = LinearRegression()

reg1.fit(drive_in_time.reshape(-1, 1), gain.reshape(-1, 1))

a2 = reg1.coef_
b2 = reg1.intercept_
a2[0][0], b2[0]

"""**Line equation** is  gain_hat = 3.766382410356517 * drive_in_time + (314.77293742936445)"""

predicted_gain = reg1.predict(drive_in_time.reshape(-1, 1))
predicted_gain

corr_coeff, _ = pearsonr(drive_in_time, gain)
corr_coeff

if len(drive_in_time) < 30:
  lack_of_fit_test(gain, predicted_gain, 0.05, 1)

else:
  lack_of_fit_test(gain, predicted_gain, 0.05, 2)

reg2 = LinearRegression()

reg2.fit(dose.reshape(-1, 1), gain.reshape(-1, 1))

a2 = reg2.coef_
b2 = reg2.intercept_
a2[0][0], b2[0]

"""**Line equation** is  gain_hat = 3.766382410356517 * drive_in_time + (314.77293742936445)"""

predicted_gain_dose = reg2.predict(dose.reshape(-1, 1))
predicted_gain_dose

if len(dose) < 30:
  lack_of_fit_test(gain, predicted_gain_dose, 0.5, 1)

else:
  lack_of_fit_test(gain, predicted_gain_dose, 0.5, 2)

"""## **Question 3**"""

year = [i for i in range(1978, 2000)]
nit_oxide = [0.73, 2.55, 2.90, 3.83, 2.53, 2.77, 3.93, 2.03, 4.39, 3.04, 3.41, 5.07, 3.95, 3.14, 3.44, 3.63, 4.50, 3.95, 5.24, 3.30, 4.36, 3.33]

plt.plot(year, nit_oxide)

year = np.array(year)
nit_oxide = np.array(nit_oxide)

reg3 = LinearRegression()

reg3.fit(year.reshape(-1, 1), nit_oxide.reshape(-1, 1))

a3 = reg3.coef_
b3 = reg3.intercept_
a3[0][0], b3[0]

"""**Line equation** is  nit_oxide_hat = 0.09019762845849802 * year + (-175.90252964426875)"""

nit_oxide_hat = reg3.predict(year.reshape(-1, 1))
nit_oxide_hat

if len(year) < 30:
  lack_of_fit_test(nit_oxide, nit_oxide_hat, 0.5, 1)

else:
  lack_of_fit_test(nit_oxide, nit_oxide_hat, 0.5, 2)

r2_score(nit_oxide, nit_oxide_hat)

plt.plot(year, nit_oxide, color='b')
plt.plot(year, nit_oxide_hat, color='r')

"""## **Question 4**"""

v = [2.27, 2.76, 3.27, 3.31, 3.70, 3.85, 4.31, 4.39, 4.42, 4.81, 4.90, 5.05, 5.21, 5.62, 5.88]
p = [2500, 365, 23700, 5491, 14000, 78200, 70700, 138000, 304500, 341948, 49375, 260200, 867023, 1640000,1092759]

"""**Part 1**"""

v = np.log2(v)
p = np.log2(p)

mymodel = np.poly1d(np.polyfit(v, p, 1))

plt.plot(v, p, 'bo', label='p')
plt.plot(v, mymodel(v), label="precicted_p", color='red')
plt.xlabel("v")
plt.ylabel("p")
plt.legend(loc='lower right', ncol=2)
plt.show()

predicted_p = mymodel(v)
ans = np.exp2(mymodel.coefficients)
#print(mymodel.coefficients)
print("a is ",ans[0]," \nb is ",ans[1])

"""**Part 2**"""

p = np.array([2500,365,23700,5491,14000,78200,70700,138000,304500,341948,49375,260200,867023,1640000,1092759])

a = np.sum(v*p)/np.sum(v**2)
fn = lambda x: a*x

plt.plot(v, p, 'bo',label='pi')
plt.plot(v,fn(v), label="precicted_p", color='red')
plt.xlabel("v")
plt.ylabel("p")
plt.legend(loc='lower right', ncol=2)
plt.show()

predicted_y = fn(v)
print("a is", a)

"""## **Question 5**"""

period = [88, 225, 365, 687, 4329, 10753, 30660, 60150]
mean_dist = [57.9, 108.2, 149.6, 227.9, 778.1, 1428.2, 2837.9, 4488.9]

period = np.log2(period)
mean_dist = np.log2(mean_dist)

my_model = np.poly1d(np.polyfit(period, mean_dist, 1))

plt.plot(period, mean_dist, 'bo',label='yi')
plt.plot(period, my_model(period), label="precicted_mean_dist", color='green')
plt.xlabel("period")
plt.ylabel("mean_dist")
plt.legend(loc='lower right', ncol=2)
plt.show()

predicted_mean_dist = my_model(period)
ans = np.exp2(my_model.coefficients)

print("a is",ans[0]," \nb is",ans[1])